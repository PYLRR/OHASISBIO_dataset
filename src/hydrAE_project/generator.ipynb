{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T08:41:25.866434Z",
     "start_time": "2024-08-27T08:41:19.792489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy import signal\n",
    "import datetime\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.data_reading.sound_data.station import StationsCatalog\n",
    "from utils.transformations.features_extractor import STFTFeaturesExtractor"
   ],
   "id": "46fd83a0a52c0f95",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 10:41:21.255393: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-27 10:41:21.342888: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 10:41:21.623126: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-27 10:41:21.623441: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-27 10:41:21.671968: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-27 10:41:21.778818: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-27 10:41:21.781905: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-27 10:41:23.317881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/plerolland/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T08:41:25.876624Z",
     "start_time": "2024-08-27T08:41:25.872718Z"
    }
   },
   "source": [
    "datasets_yaml = \"/home/plerolland/Bureau/dataset.yaml\"\n",
    "out_root = \"/media/plerolland/LaBoite/spectros\"\n",
    "\n",
    "DELTA = datetime.timedelta(seconds=200)\n",
    "TIME_RES = 0.5\n",
    "F_RES = 0.5\n",
    "overlap = 0.1"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-27T08:41:26.245076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for year in [2020]:\n",
    "    print(f\"Processing year {year}\")\n",
    "    \n",
    "    stations = StationsCatalog(datasets_yaml).filter_out_undated().filter_out_unlocated()\n",
    "    stations = stations.ends_after(datetime.datetime(year,1,1) - datetime.timedelta(days=1))\n",
    "    stations = stations.starts_before(datetime.datetime(year+1,1,1) + datetime.timedelta(days=1))\n",
    "    stft_computer = STFTFeaturesExtractor(None, vmin=60, vmax=110)\n",
    "    \n",
    "    for station in stations:\n",
    "        out_station = f'{out_root}/{year}/{station.name}-{station.date_start.year}'\n",
    "        Path(out_station).mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        csv_file = f'{out_station}/index.csv'\n",
    "        if not Path(csv_file).is_file():\n",
    "            with open(csv_file, \"w\") as f:\n",
    "                f.write(\"day,datetime_start\\n\")\n",
    "                \n",
    "        done = {}\n",
    "        with open(csv_file, \"r\") as f:\n",
    "            content = f.readlines()[1:]\n",
    "            for line in content:\n",
    "                line = line[:-1].split(\",\")\n",
    "                line[0] = int(line[0])\n",
    "                if line[0] not in done:\n",
    "                    done[line[0]] = []\n",
    "                done[line[0]].append(line[1])\n",
    "        \n",
    "        print(f\"Processing station {station.name}\")\n",
    "        manager = station.get_manager()\n",
    "        manager.cache_size=1\n",
    "        stft_computer.manager = manager\n",
    "        stft_computer.nperseg = int(manager.sampling_f / F_RES)\n",
    "        stft_computer.overlap = 1 - TIME_RES * manager.sampling_f / stft_computer.nperseg\n",
    "        sta_offset = int(10 * manager.sampling_f)\n",
    "        \n",
    "        \n",
    "        start = max(datetime.datetime(year,1,1), station.date_start)\n",
    "        end = min(datetime.datetime(year+1,1,1), station.date_end)\n",
    "        steps = math.ceil((end-start)/(DELTA*(1-overlap)))\n",
    "        \n",
    "        peaks_kept = []\n",
    "        batch = []\n",
    "        for i in tqdm(range(1, steps)):\n",
    "            seg_start = start + i*(1-overlap)*DELTA\n",
    "            seg_start_str = seg_start.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            seg_end = seg_start+DELTA\n",
    "    \n",
    "            if seg_end > end:\n",
    "                continue # we don't make smaller spectrograms in the ends of the datasets\n",
    "            \n",
    "            day = seg_start.timetuple().tm_yday\n",
    "            if day in done and seg_start_str in done[day]:\n",
    "                continue  # already done\n",
    "            \n",
    "            out = f'{out_station}/{day}'\n",
    "            Path(out).mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            data = manager.getSegment(seg_start, seg_end)\n",
    "            stft_features = stft_computer._get_features(data)\n",
    "            stft_computer._save_features(stft_features, f'{out}/{seg_start_str}.png')\n",
    "            \n",
    "            data = data if data is not None else manager.getSegment(seg_start, seg_end)\n",
    "            pts_sta = np.square(data)\n",
    "            lta = np.sqrt(np.mean(pts_sta))\n",
    "            stas = np.sqrt(np.convolve(pts_sta, np.ones(sta_offset) / sta_offset, mode='same')[::int(stft_computer.nperseg*(1-stft_computer.overlap))])\n",
    "            sta_lta = stas / lta\n",
    "            if stft_features is not None and len(sta_lta) != stft_features[2].shape[1]:\n",
    "                sta_lta = signal.resample(sta_lta,stft_features[2].shape[1])\n",
    "            np.save(f'{out}/{seg_start_str}_stalta.npy', sta_lta)\n",
    "                \n",
    "            with open(csv_file, \"a\") as f:\n",
    "                f.write(f'{day},{seg_start.strftime(\"%Y%m%d_%H%M%S\")}\\n')\n",
    "    \n",
    "        print(f\"Station {station.name} processed\")"
   ],
   "id": "f4a215af563d42fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2020\n",
      "Processing station ELAN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/168322 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "208c923e74a24040b3d0f6b55ca3f8a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station ELAN processed\n",
      "Processing station MADW\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/172564 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbb7f007adaf407299ac81093602b650"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station MADW processed\n",
      "Processing station NEAMS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/163458 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "297935719c7742b7886ed4b20302ddcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station NEAMS processed\n",
      "Processing station RTJ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/140896 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc4019623d9c4eab913082e9229a1ff8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station RTJ processed\n",
      "Processing station SSEIR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/162100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa03b60734b14061821eb4435cce185a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station SSEIR processed\n",
      "Processing station SWAMS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/164954 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6704a35c7e004ebc97735b78bbd468f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"/me9ia/plerolland/akoustik/spectros/2018/ELAN/16/20180116_174204\"\n",
    "img = mpimg.imread(f'{path}.png')\n",
    "sta_lta = np.load(f'{path}_stalta.npy')\n",
    "\n",
    "_ = plt.figure(1)\n",
    "plt.imshow(img, aspect='auto', cmap='jet')\n",
    "\n",
    "_ = plt.figure(2)\n",
    "plt.plot(sta_lta)\n"
   ],
   "id": "a526da7766709ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7eb58634e6379978",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
