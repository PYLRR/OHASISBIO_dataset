{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.eval.eval_utils import evaluate_peaks, compute_ROC, compute_residuals_histogram\n",
    "from utils.training.metrics import accuracy_for_segmenter, AUC_for_segmenter\n",
    "from utils.training.data_loading import get_line_to_dataset_waveform\n",
    "from utils.training.keras_models import AcousticPhaseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f78cc2ffd94e845"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/path/to/the/dataset\"  # path where we expect to find directories named \"postives\", \"negatives\" and a csv file\n",
    "BATCH_SIZE = 64\n",
    "epoch = 22  # epoch checkpoint that we want to load\n",
    "CHECKPOINT = f\".../../../data/model_saves/AcousticPhaseNet/all/cp-{{epoch:04d}}.ckpt\"  # path of the checkpoint to load\n",
    "OUTPUT_DIR = \"AcousticPhaseNet/dataset\"  # directory where to output files, in the data folder\n",
    "\n",
    "SIZE = int(2**(np.ceil(np.log2(100*240+1))))  # number of points in each file rounded to the next pow of 2\n",
    "CHANNELS = 1  # 1 means grayscale 3 RGB\n",
    "DURATION_S = 100  # duration of the spectrograms in s\n",
    "OBJECTIVE_CURVE_WIDTH = 10  # defines width of objective function in s\n",
    "\n",
    "ALLOWED_ERROR_S = 10  # tolerance when evaluating and time distance allowed between two peaks in the probabilities distribution\n",
    "MIN_PROBA = 0.0001  # minimum value of the output of the segmenter model to record it\n",
    "TIME_RES = DURATION_S / SIZE\n",
    "\n",
    "data_loader = get_line_to_dataset_waveform(size=SIZE, duration_s=DURATION_S, objective_curve_width=OBJECTIVE_CURVE_WIDTH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbfc200168bad7b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26b110abc64f05ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AcousticPhaseNet\n",
    "m = model(SIZE)\n",
    "m.load_weights(CHECKPOINT)\n",
    "m.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "            loss=tf.losses.binary_crossentropy,\n",
    "            metrics=[accuracy_for_segmenter, AUC_for_segmenter()])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7286e71efcad954"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82cba6d5537403f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# open the csv listing data, shuffling the lines\n",
    "with open(ROOT_DIR + \"/dataset.csv\", \"r\") as f:\n",
    "    csv_reader = csv.reader(f, delimiter=\",\")\n",
    "    lines = list(csv_reader)\n",
    "lines = shuffle(lines)\n",
    "print(len(lines), \"files found\")\n",
    "x, y = data_loader(lines)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((list(x), list(y)))\n",
    "dataset = dataset.batch(batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "102d1c8dba1213bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model execution and peaks finding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebe1e3b286f20c46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "detected_peaks = []\n",
    "ground_truth_peaks = []\n",
    "for x, y in tqdm(dataset, total=1+int(len(lines)/BATCH_SIZE)):\n",
    "    # predict the output for a whole batch\n",
    "    predicted = m.predict(x, verbose=False)\n",
    "    for i, p in enumerate(predicted):\n",
    "        # for each output, apply a peaks finding algorithm\n",
    "        detected_peaks.append(find_peaks(p, height=MIN_PROBA, distance=ALLOWED_ERROR_S/TIME_RES))\n",
    "        _y = y[i,:,0] if len(y.shape) == 3 else y[i, :]\n",
    "        ground_truth_peaks.append(find_peaks(_y, height=MIN_PROBA, distance=ALLOWED_ERROR_S/TIME_RES))\n",
    "        \n",
    "detected_peaks = [[(d[0][i]*TIME_RES, d[1][\"peak_heights\"][i]) for i in range(len(d[0]))] for d in detected_peaks]\n",
    "ground_truth_peaks = [d[0]*TIME_RES for d in ground_truth_peaks]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c41476edad4cc8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Peaks statistics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dfeb51e3b40b8d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Get number of peaks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b77becc39a4ae9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i,j = 0,0\n",
    "for idx in range(len(detected_peaks)):\n",
    "    i+=len(detected_peaks[idx])\n",
    "    j+=len(ground_truth_peaks[idx])\n",
    "print(f\"{i} peaks found out of {j}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd8f8d460ea3d46d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ROC curve computing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdcf6ea0de5c1388"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TP, FP, TP_per_seg, TN_per_seg, FP_per_seg, FN_per_seg, P_per_seg, N_per_seg = evaluate_peaks(ground_truth_peaks, detected_peaks, ALLOWED_ERROR_S)\n",
    "TPr, FPr = compute_ROC(TP_per_seg, P_per_seg, FP_per_seg, N_per_seg, thresh_delta=0.001)\n",
    "plt.plot(FPr, TPr)\n",
    "np.save(f\"../../../data/npy/{OUTPUT_DIR}/FPr.npy\", FPr)\n",
    "np.save(f\"../../../data/npy/{OUTPUT_DIR}/TPr.npy\", TPr)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"TP rate\")\n",
    "plt.xlabel(\"FP rate\")\n",
    "plt.title(\"ROC curve\")\n",
    "plt.savefig(f\"../../../data/figures/{OUTPUT_DIR}/ROC.png\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6460d120076046e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Residuals histogram computing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68ac5ae43454cd97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BAR_WIDTH = 0.9\n",
    "step = 40*TIME_RES\n",
    "\n",
    "extremum = step * np.round(ALLOWED_ERROR_S / step)\n",
    "allowed_d = np.arange(-extremum, extremum+step, step)\n",
    "TP_by_distance = compute_residuals_histogram(allowed_d, TP)\n",
    "\n",
    "np.save(f\"../../../data/npy/{OUTPUT_DIR}/TP_by_distance.npy\", TP_by_distance)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "plt.bar(allowed_d, TP_by_distance, width=BAR_WIDTH, align='center')\n",
    "plt.xticks(allowed_d)\n",
    "plt.xlim(allowed_d[0]-0.5-(1-BAR_WIDTH), allowed_d[-1]+0.5+(1-BAR_WIDTH))\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "plt.xlabel('Time residuals (s)', fontsize=12)\n",
    "plt.ylabel('Proportion of detections', fontsize=12)\n",
    "plt.savefig(f'../../../data/figures/{OUTPUT_DIR}/histogram.png', bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1b78cfbdecdb03c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "70846036930c961c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
