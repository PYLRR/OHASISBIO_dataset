{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook enables to investigate about TiSSNet features."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a594b3b72bb1a423"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from keras import Model\n",
    "from keras.src.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.training.data_loading import load_spectro\n",
    "from utils.training.keras_models import TiSSNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4666804f21383f0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fd32f2fcf455222"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 22  # epoch checkpoint that we want to load\n",
    "CHECKPOINT = f\"../../../../data/model_saves/TiSSNet/cp-{{epoch:04d}}.ckpt\" # path of TiSSNet checkpoint to load\n",
    "SIZE = (128, 186)  # shape of the input images\n",
    "\n",
    "model = TiSSNet(SIZE)\n",
    "model.load_weights(CHECKPOINT)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization: listing the conv layers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdc7eff86913d132"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_layers = []\n",
    "for layer in model.layers:\n",
    "    if 'conv' not in layer.name: # maxpooling, flattening\n",
    "        continue\n",
    "    filters, biases = layer.get_weights()\n",
    "    conv_layers.append(layer)\n",
    "    print(layer.name, filters.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "573334aa329765d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filters visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a89e2131818b94c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "block_id = 0  # block we want to inspect (blocks are layers where data keeps the same shape)\n",
    "conv_id = 1  # conv layer we want to inspect in the chosen block (from 0 to 2)\n",
    "n_filters, n_channels = 16, 16  # choice of the nb of filters to inspect, and the nb of channels for each\n",
    "# reminder : a layer with n filters has n channels as output, but maybe more or less as input\n",
    "\n",
    "layer = 3*block_id+conv_id\n",
    "filters, biases = conv_layers[layer].get_weights()\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)  # normalization of filters\n",
    "\n",
    "plot_idx = 1\n",
    "plt.subplots(n_filters, n_channels, figsize=(20,20))\n",
    "for i in range(n_filters):\n",
    "    f = filters[:, :, :, i]\n",
    "    # plot some channels\n",
    "    for j in range(n_channels):\n",
    "         ax = plt.subplot(n_filters, n_channels, plot_idx)\n",
    "         ax.set_xticks([])\n",
    "         ax.set_yticks([])\n",
    "         plt.imshow(f[:, :, j], cmap='gray')\n",
    "         plot_idx += 1\n",
    "# show the figure\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f69d395321aef8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filters outputs visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "308ad9400c770e71"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_path = \".png\"  # path of a spectrogram to show\n",
    "img = load_spectro(img_path, SIZE, 1)  # prepare the spectrogram to feed the model\n",
    "plt.imshow(img, cmap=\"inferno\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4018e87100d7d478"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "block_id = 0  # block we want to inspect (blocks are layers where data keeps the same shape)\n",
    "conv_id = 0  # conv layer we want to inspect in the chosen block (from 0 to 2)\n",
    "square = 2  # side of the figure. square^2 convolution outputs will be shown\n",
    "\n",
    "layer = 3*block_id+conv_id\n",
    "# predict output at the chosen layer\n",
    "temp_model = Model(inputs=model.inputs, outputs=conv_layers[layer].output)\n",
    "feature_maps = temp_model.predict((img.numpy()).reshape(1, SIZE[0], SIZE[1], 1))\n",
    "\n",
    "plot_idx = 1\n",
    "aspect = 2**(min(block_id,1))*4**(max(block_id-1,0))  # output, kept as a square\n",
    "plt.subplots(square, square, figsize=(16,12))\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "        ax = plt.subplot(square, square, plot_idx)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.imshow(feature_maps[0, :, :, plot_idx-1], cmap='gray', aspect=aspect)\n",
    "        plot_idx += 1\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../../../data/figures/conv1_features.png\", dpi=150, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "435607151ba07d95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Heatmaps to show the contribution of each pixel to the output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "734c37a6095799c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "block_id = 0  # block we want to inspect (blocks are layers where data keeps the same shape)\n",
    "conv_id = 0  # conv layer we want to inspect in the chosen block (from 0 to 2)\n",
    "square = 2  # side of the figure. square^2 convolution outputs will be shown\n",
    "\n",
    "layer = 3*block_id+conv_id\n",
    "\n",
    "# get prediction of the model and compute its gradient\n",
    "heatmap_model = Model(inputs=model.inputs, outputs=[conv_layers[layer].output, model.output])\n",
    "with tf.GradientTape() as gtape:\n",
    "    conv_output, predictions = heatmap_model((img.numpy()).reshape(1, SIZE[0], SIZE[1], 1))\n",
    "    loss = K.mean(predictions[0, np.argmax(predictions[0])])\n",
    "    grads = gtape.gradient(loss, conv_output)\n",
    "\n",
    "# plot the resulting heatmaps\n",
    "plt.subplots(square, square, figsize=(16,12))\n",
    "plot_idx=0\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "        plt.subplot(square, square, plot_idx+1)\n",
    "        \n",
    "        # multiply the output of the filter by its gradient\n",
    "        heatmap = np.multiply(np.array(grads)[:,:,:,plot_idx], conv_output[:,:,:,plot_idx])\n",
    "        heatmap = np.array(heatmap)\n",
    "        heatmap = np.maximum(heatmap, 0)\n",
    "        max_heat = np.max(heatmap)\n",
    "        heatmap /= max_heat\n",
    "    \n",
    "        plt.imshow(heatmap.reshape((SIZE[0],SIZE[1],1)), cmap='jet')\n",
    "        plt.axis('off')\n",
    "        plot_idx += 1\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../../../data/figures/conv1_heatmaps.png\", dpi=150, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24d5085097963910"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output fitting\n",
    "Starting from an image and an objective output, tune the image to minimize the loss of the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da788118a2901fd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we define a gaussian that the model will try to match\n",
    "mean = 60\n",
    "var = 4\n",
    "# now choose an input image from which the optimization process will start\n",
    "start_img_path = \".png\"\n",
    "\n",
    "law = scipy.stats.norm(mean, var)\n",
    "expected_output = [law.pdf(i) for i in range(SIZE[1])]\n",
    "\n",
    "# plot the output we want the network to give\n",
    "plt.plot(expected_output)\n",
    "plt.xlim(0, SIZE[1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "start_img = load_spectro(start_img_path, SIZE, 1)\n",
    "\n",
    "# show the input image the network starts with\n",
    "plt.imshow(start_img, cmap=\"inferno\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eb784f243fe90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = Adam(learning_rate=0.1)\n",
    "num_iterations = 1000\n",
    "\n",
    "# assign the image as a tf variable for optimization\n",
    "input_to_optimize = tf.Variable(np.copy(start_img).reshape((1, SIZE[0], SIZE[1], 1)))\n",
    "\n",
    "# define the loss function as the difference between the actual output and the wanted output\n",
    "@tf.function\n",
    "def loss():\n",
    "    output = model(input_to_optimize, training=False)\n",
    "    return tf.keras.losses.mean_squared_error(expected_output, output)\n",
    "\n",
    "# optimization loop\n",
    "for i in (pbar:=tqdm(range(num_iterations))):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "        tape.watch(input_to_optimize)\n",
    "        output = model(input_to_optimize, training=False)\n",
    "        \n",
    "        # compute loss and gradient\n",
    "        l = tf.keras.losses.mean_squared_error(expected_output, output)\n",
    "        g = tape.gradient(l, input_to_optimize)\n",
    "        \n",
    "        # apply optimization\n",
    "        optimizer.apply_gradients(zip([g], [input_to_optimize]))\n",
    "        \n",
    "        # show the loss in the progress bar\n",
    "        pbar.set_postfix_str(str(l))\n",
    "\n",
    "print(\"Final loss:\", loss().numpy())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a516678f6ee14704"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# take a look at the modified image\n",
    "new_img = input_to_optimize.numpy().reshape((128,186,1))\n",
    "plt.imshow(new_img, cmap=\"inferno\")\n",
    "plt.show()\n",
    "# plot the current output of the network given this image as input, together with the wanted output\n",
    "plt.plot(expected_output, label=\"objective\")\n",
    "plt.plot(model.predict(input_to_optimize).reshape(SIZE[1]), label=\"optimization result\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1452321e1315865"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "95b19752f49e90d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
