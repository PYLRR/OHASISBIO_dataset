{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook enables to train AcousticPhaseNet model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463e827b9bc504b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from src.utils.training.metrics import accuracy_for_segmenter, AUC_for_segmenter\n",
    "from src.utils.training.data_loading import get_line_to_dataset_waveform\n",
    "from src.utils.training.keras_models import AcousticPhaseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "827f3bbab60d0d1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/path/to/the/dataset\"  # path where we expect to find directories named \"postives\", \"negatives\" and a csv file\n",
    "SEED = 0  # Seed for RNG\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "CHECKPOINTS_DIR = \"../../../../data/model_saves/AcousticPhaseNet\"  # directory where the model will save its history and checkpoints\n",
    "\n",
    "FOLDS = 5  # number of folds for the cross-validation\n",
    "SIZE = int(2**(np.ceil(np.log2(100*240+1))))  # number of points in each file rounded to the next pow of 2\n",
    "DURATION_S = 100  # duration of the files in s\n",
    "OBJECTIVE_CURVE_WIDTH = 10  # defines width of objective function in s\n",
    "\n",
    "data_loader = get_line_to_dataset_waveform(size=SIZE, duration_s=DURATION_S, objective_curve_width=OBJECTIVE_CURVE_WIDTH)\n",
    "model = AcousticPhaseNet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71fca84d6b1cb5d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a41f75bd3a90ee2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# open the csv listing data, shuffling the lines\n",
    "with open(ROOT_DIR + \"/dataset.csv\", \"r\") as f:\n",
    "    csv_reader = csv.reader(f, delimiter=\",\")\n",
    "    lines = list(csv_reader)\n",
    "random.Random(SEED).shuffle(lines)\n",
    "print(len(lines), \"files found\")\n",
    "\n",
    "# load data\n",
    "pos = [l for l in lines if l[1]==\"positive\"]\n",
    "xpos, ypos = data_loader(pos)\n",
    "neg = [l for l in lines if l[1]==\"negative\"]\n",
    "xneg, yneg = data_loader(neg)\n",
    "print(f\"{len(xpos)} positive files found and {len(xneg)} negative files found\")\n",
    "\n",
    "# merge and shuffle positives and negatives\n",
    "xd = np.concatenate((xpos, xneg[:len(xpos)]))\n",
    "extra_x = xneg[len(xpos):]\n",
    "yd = np.concatenate((ypos, yneg[:len(ypos)]))\n",
    "extra_y = yneg[len(ypos):]\n",
    "xd, yd = shuffle(xd, yd)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b39854a497accbc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aacb8d85a7879dff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = 8\n",
    "lines = 4\n",
    "batch_number = 1  # number of the batch we want to inspect\n",
    "\n",
    "to_show = cols * lines\n",
    "plt.figure(figsize=(cols*2.5, lines*5))\n",
    "shown=0\n",
    "for i in range(batch_number*BATCH_SIZE, batch_number*BATCH_SIZE+to_show):\n",
    "    x, y = xd[i], yd[i]\n",
    "    \n",
    "    ax1 = plt.subplot(lines*2, cols, 1 + shown%cols + cols*2*(shown//cols))\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel(\"pressure\")\n",
    "    plt.plot(x)\n",
    "    ax1.set_xlim([0, SIZE])\n",
    "\n",
    "    ax2 = plt.subplot(lines*2, cols, 1 + shown%cols + cols*2*(shown//cols) + cols)\n",
    "\n",
    "    ax2.plot(y, label='ground truth')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "    ax2.set_xlim([0, SIZE])\n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.set_xlabel(\"time\")\n",
    "    ax2.set_ylabel(\"probability\")\n",
    "\n",
    "    shown += 1\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79c8cde4faea208c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross-validation training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de98967d74adc400"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(FOLDS):\n",
    "    path_prefix = f'{CHECKPOINTS_DIR}/FOLD-{i}'\n",
    "    history_file = f'{path_prefix}/history.pkl'\n",
    "    \n",
    "    if os.path.isfile(history_file):\n",
    "        print(f\"fold {i} already has an history file, skipping it\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"starting training of fold {i}\")\n",
    "    m = model()\n",
    "    m.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "            loss=tf.losses.binary_crossentropy,\n",
    "            metrics=[accuracy_for_segmenter, AUC_for_segmenter()])\n",
    "    m.build((BATCH_SIZE, SIZE))\n",
    "\n",
    "    if i==0:\n",
    "        m.summary()\n",
    "\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'{path_prefix}/cp-{{epoch:04d}}.ckpt', save_weights_only=True, verbose=1)\n",
    "\n",
    "    # we make the folds right before using them to save memory\n",
    "    start_valid_idx = int(len(xd) * i / FOLDS)\n",
    "    end_valid_idx = int(len(xd) * (i + 1) / FOLDS)\n",
    "    \n",
    "    x_train = np.concatenate((xd[:start_valid_idx], xd[end_valid_idx:]))\n",
    "    y_train = np.concatenate((yd[:start_valid_idx], yd[end_valid_idx:]))\n",
    "    \n",
    "    x_valid = xd[start_valid_idx:end_valid_idx]\n",
    "    y_valid = yd[start_valid_idx:end_valid_idx]\n",
    "    \n",
    "    x_train, y_train = shuffle(x_train, y_train)\n",
    "    x_valid, y_valid = shuffle(x_valid, y_valid)\n",
    "    y_train = np.reshape(y_train, (-1, SIZE))\n",
    "    y_valid = np.reshape(y_valid, (-1, SIZE))\n",
    "\n",
    "    history = m.fit(x_train, y_train,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=(x_valid,y_valid),\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[cp_callback]\n",
    "        )\n",
    "    \n",
    "    with open(history_file, 'wb') as f:\n",
    "        pickle.dump(history.history, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18e249d1ba681c9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training on all the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "212f6b702b3c3b6e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_train_x, all_train_y = np.concatenate((xd, extra_x)), np.concatenate((yd, extra_y))\n",
    "all_train_x, all_train_y = shuffle(all_train_x, all_train_y)\n",
    "\n",
    "m = model()\n",
    "\n",
    "m.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "        loss=tf.losses.binary_crossentropy,\n",
    "        metrics=[accuracy_for_segmenter, AUC_for_segmenter()])\n",
    "\n",
    "m.build((BATCH_SIZE, SIZE))\n",
    "\n",
    "m.summary()\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f\"{CHECKPOINTS_DIR}/cp-{{epoch:04d}}.ckpt\",\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "m.fit(\n",
    "        all_train_x, all_train_y,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[cp_callback]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "285778b5713bc0a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot some examples of outputs of the network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62275743454c4a3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m = model()\n",
    "epoch = 22  # epoch checkpoint that we want to load\n",
    "m.load_weights(f\"{CHECKPOINTS_DIR}/checkpoints/cp-{{epoch:04d}}.ckpt\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8866c9c507afa227"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = 4\n",
    "lines = 2\n",
    "to_skip = 2\n",
    "\n",
    "to_show = cols * lines\n",
    "to_skip *= to_show\n",
    "plt.figure(figsize=(cols*5, lines*10))\n",
    "shown=0\n",
    "for i in range(to_skip, to_skip+to_show):\n",
    "    x, y = xd[i], yd[i]\n",
    "    \n",
    "    ax1 = plt.subplot(lines*2, cols, 1 + shown%cols + cols*2*(shown//cols))\n",
    "    plt.xlabel(\"time\")\n",
    "    plt.ylabel(\"normalized pressure\")\n",
    "    plt.plot(x)\n",
    "    ax1.set_xlim([0, SIZE])\n",
    "\n",
    "    ax2 = plt.subplot(lines*2, cols, 1 + shown%cols + cols*2*(shown//cols) + cols)\n",
    "    \n",
    "    predicted = m.predict(np.reshape(x, (1, SIZE)), verbose=False)[0]\n",
    "    ax2.plot(predicted, label='predicted')\n",
    "    ax2.plot(y, label='ground truth')\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.set_xlim([0, SIZE])\n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.set_xlabel(\"time\")\n",
    "    ax2.set_ylabel(\"probability\")\n",
    "\n",
    "    shown += 1\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a7fab59502d5011"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
